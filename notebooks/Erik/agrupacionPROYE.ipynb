{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFaOxJ_Zpeyo"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWA6-HVIrVRp",
    "outputId": "e2f5d441-a25c-4633-dc3e-c47a14ea08b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 180219 entries, 0 to 180218\n",
      "Data columns (total 48 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ID          180219 non-null  object \n",
      " 1   EDO         180219 non-null  int64  \n",
      " 2   MES         180219 non-null  int64  \n",
      " 3   ANIO        180219 non-null  int64  \n",
      " 4   MPIO        180219 non-null  int64  \n",
      " 5   HORA        180219 non-null  int64  \n",
      " 6   MINUTOS     180219 non-null  int64  \n",
      " 7   DIA         180219 non-null  int64  \n",
      " 8   DIASEMANA   180219 non-null  int64  \n",
      " 9   URBANA      180219 non-null  int64  \n",
      " 10  SUBURBANA   180219 non-null  int64  \n",
      " 11  TIPACCID    180219 non-null  int64  \n",
      " 12  AUTOMOVIL   180219 non-null  int64  \n",
      " 13  CAMPASAJ    180219 non-null  int64  \n",
      " 14  MICROBUS    180219 non-null  int64  \n",
      " 15  PASCAMION   180219 non-null  int64  \n",
      " 16  OMNIBUS     180219 non-null  int64  \n",
      " 17  TRANVIA     180219 non-null  int64  \n",
      " 18  CAMIONETA   180219 non-null  int64  \n",
      " 19  CAMION      180219 non-null  int64  \n",
      " 20  TRACTOR     180219 non-null  int64  \n",
      " 21  FERROCARRI  180219 non-null  int64  \n",
      " 22  MOTOCICLET  180219 non-null  int64  \n",
      " 23  BICICLETA   180219 non-null  int64  \n",
      " 24  OTROVEHIC   180219 non-null  int64  \n",
      " 25  CAUSAACCI   180219 non-null  int64  \n",
      " 26  CAPAROD     180219 non-null  int64  \n",
      " 27  SEXO        180219 non-null  int64  \n",
      " 28  ALIENTO     180219 non-null  int64  \n",
      " 29  CINTURON    180219 non-null  int64  \n",
      " 30  EDAD        180219 non-null  int64  \n",
      " 31  CONDMUERTO  180219 non-null  int64  \n",
      " 32  CONDHERIDO  180219 non-null  int64  \n",
      " 33  PASAMUERTO  180219 non-null  int64  \n",
      " 34  PASAHERIDO  180219 non-null  int64  \n",
      " 35  PEATMUERTO  180219 non-null  int64  \n",
      " 36  PEATHERIDO  180219 non-null  int64  \n",
      " 37  CICLMUERTO  180219 non-null  int64  \n",
      " 38  CICLHERIDO  180219 non-null  int64  \n",
      " 39  OTROMUERTO  180219 non-null  int64  \n",
      " 40  OTROHERIDO  180219 non-null  int64  \n",
      " 41  TOTMUERTOS  180219 non-null  int64  \n",
      " 42  TOTHERIDOS  180219 non-null  int64  \n",
      " 43  CLASE       180219 non-null  int64  \n",
      " 44  CALLE1      180219 non-null  object \n",
      " 45  CALLE2      175938 non-null  object \n",
      " 46  LONGITUD    180219 non-null  float64\n",
      " 47  LATITUD     180219 non-null  float64\n",
      "dtypes: float64(2), int64(43), object(3)\n",
      "memory usage: 66.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-19b64c38e5df>:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/content/nacional.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/content/nacional.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "QJBIhDl-sR6i",
    "outputId": "5597233c-bb7e-42ee-cb0a-a4f2f09b24ba"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sobremuestreado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a22679aed2a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Select features for clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'TIPACCID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LONGITUD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LATITUD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CAUSAACCI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DIASEMANA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TOTMUERTOS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sobremuestreado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Handle missing values (replace with mean for numerical features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_sobremuestreado' is not defined"
     ]
    }
   ],
   "source": [
    "# prompt: Use EDO for Clusters and TIPACCID, LONGITUD, LALTITUD, as features for clustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features for clustering\n",
    "features = ['TIPACCID', 'LONGITUD', 'LATITUD','CAUSAACCI','DIASEMANA','TOTMUERTOS']\n",
    "X = df_sobremuestreado[features]\n",
    "\n",
    "# Handle missing values (replace with mean for numerical features)\n",
    "for col in features:\n",
    "    if X[col].isnull().any():\n",
    "      X[col].fillna(X[col].mean(), inplace=True)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply KMeans clustering (you can adjust the number of clusters)\n",
    "kmeans = KMeans(n_clusters=5, random_state=0) # Example with 5 clusters\n",
    "df_sobremuestreado['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Now 'df' contains a new 'cluster' column with the cluster assignments.\n",
    "# You can further explore the clusters using these labels\n",
    "print(df.head())\n",
    "\n",
    "# Visualization (example using the first two features)\n",
    "plt.scatter(df['LONGITUD'], df['LATITUD'], c=df['cluster'])\n",
    "plt.xlabel('LONGITUD')\n",
    "plt.ylabel('LATITUD')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "usjLKuAbt0K8",
    "outputId": "fe03dc63-de8b-47b6-90be-e9f0bb65026e"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b33d104fb0d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Visualize the clusters (example with two features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TIPACCID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EDO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TIPACCID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EDO'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompt: grafica la agrupacion echa con kmeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize the clusters (example with two features)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['TIPACCID'], df['EDO'], c=df['cluster'], cmap='viridis')\n",
    "plt.xlabel('TIPACCID')\n",
    "plt.ylabel('EDO')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "42e8vj4wuhVF",
    "outputId": "02331dde-940a-4f32-a5a9-62ec52764aa7"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d7afbe93e7b3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a mapping of cluster numbers to accident types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcluster_accident_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Find the most frequent accident type within each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmost_frequent_accident_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TIPACCID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster'"
     ]
    }
   ],
   "source": [
    "# prompt: ver que tipo de accidente va con cada color\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'TIPACCID' and 'cluster' columns\n",
    "\n",
    "# Create a mapping of cluster numbers to accident types\n",
    "cluster_accident_mapping = {}\n",
    "for cluster in df['cluster'].unique():\n",
    "    # Find the most frequent accident type within each cluster\n",
    "    most_frequent_accident_type = df[df['cluster'] == cluster]['TIPACCID'].mode().iloc[0]\n",
    "    cluster_accident_mapping[cluster] = most_frequent_accident_type\n",
    "\n",
    "# Print the mapping\n",
    "for cluster, accident_type in cluster_accident_mapping.items():\n",
    "    print(f\"Cluster {cluster}: {accident_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "gqa2Qhm3zOlC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suponiendo que ya tienes tu dataframe llamado \"df\"\n",
    "# Creamos un diccionario para guardar los dataframes por estado\n",
    "dfs_por_estado = {}\n",
    "\n",
    "# Iteramos sobre los números de estados (1 al 32)\n",
    "for estado in range(1, 33):\n",
    "    # Filtramos los datos para cada estado y lo guardamos en el diccionario\n",
    "    dfs_por_estado[f'df_{estado}'] = df_sobremuestreado[df_sobremuestreado['EDO'] == estado]\n",
    "\n",
    "# Ahora, dfs_por_estado contiene todos los dataframes separados, como df_1, df_2, etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "2_nLaGQ8d8ZC"
   },
   "outputs": [],
   "source": [
    "# Supongamos que ya tienes el diccionario dfs_por_estado\n",
    "# Por ejemplo, para ver el head() del dataframe correspondiente al estado 1:\n",
    "dfs_por_estado['df_1'].head()\n",
    "dfs_por_estado['df_2'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WYRSuW4eFEP"
   },
   "outputs": [],
   "source": [
    "NEW_TIPACCID = df['TIPACCID'].drop([0,2, 3], axis=0)\n",
    "# Use the correct method name 'drop' and specify axis=0 to drop rows by index.\n",
    "NEW_TIPACCID.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sq8NSzU-iYzt"
   },
   "outputs": [],
   "source": [
    "# prompt: reduce el columna de TIPACCID a solo (1, 4, 7, 10)\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'TIPACCID' column\n",
    "\n",
    "# Create a list of allowed TIPACCID values\n",
    "allowed_values = [1, 4, 7, 10]\n",
    "\n",
    "# Filter the DataFrame to keep only rows with TIPACCID in the allowed list\n",
    "dfs_por_estado['df_1'] = dfs_por_estado['df_1'][dfs_por_estado['df_1']['TIPACCID'].isin(allowed_values)]\n",
    "\n",
    "# Now 'df' contains only the rows with TIPACCID values 1, 4, 7, or 10\n",
    "dfs_por_estado['df_1'].TIPACCID.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsLLS4dFeSoY"
   },
   "outputs": [],
   "source": [
    "# prompt: Use EDO for Clusters and TIPACCID, LONGITUD, LALTITUD, as features for clustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "features = ['TIPACCID', 'LATITUD','LONGITUD']\n",
    "\n",
    "X = dfs_por_estado['df_9'][features].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=123)\n",
    "dfs_por_estado['df_9']['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "\n",
    "print(dfs_por_estado['df_9'].head())\n",
    "\n",
    "# Visualization (example using the first two features)\n",
    "plt.scatter(dfs_por_estado['df_9']['TIPACCID'],dfs_por_estado['df_9']['LONGITUD'], dfs_por_estado['df_9']['LATITUD'], c=dfs_por_estado['df_9']['cluster'], cmap='viridis', alpha=0.7)\n",
    "plt.xlabel('DIASEMANA')\n",
    "plt.ylabel('TOTAL MUERTOS')\n",
    "plt.title('KMeans Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6c32f8uV_Ai"
   },
   "outputs": [],
   "source": [
    "# prompt: vizualizar los 2 features del kmeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualization (example using the first two features)\n",
    "plt.scatter(dfs_por_estado['df_9']['LONGITUD'], dfs_por_estado['df_9']['LATITUD'], c=dfs_por_estado['df_9']['cluster'], cmap='viridis')\n",
    "plt.xlabel('Longitud')\n",
    "plt.ylabel('Latitud')\n",
    "plt.title('KMeans Clustering Results para el estado 9')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4pSBskK7fUH"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "features_to_visualize = ['TIPACCID', 'ALIENTO', 'TOTMUERTOS']  # Adjust as needed\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "for cluster in dfs_por_estado['df_9']['cluster'].unique():\n",
    "    cluster_data = dfs_por_estado['df_9'][dfs_por_estado['df_9']['cluster'] == cluster]\n",
    "    ax.scatter(\n",
    "        cluster_data[features_to_visualize[0]],\n",
    "        cluster_data[features_to_visualize[1]],\n",
    "        cluster_data[features_to_visualize[2]],\n",
    "        label=f'Cluster {cluster}',\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "\n",
    "ax.set_xlabel(features_to_visualize[0])\n",
    "ax.set_ylabel(features_to_visualize[1])\n",
    "ax.set_zlabel(features_to_visualize[2])\n",
    "ax.set_title('3D Visualization of Clusters with Features')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4VHsDBI-2Uh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWbRDoUNfT9d"
   },
   "outputs": [],
   "source": [
    "# prompt: ver que tipo de accidente va con cada color\n",
    "\n",
    "# Assuming 'df_1' is your DataFrame with 'TIPACCID', 'cluster', and 'color' columns\n",
    "\n",
    "# Create a mapping of cluster numbers to accident types and colors\n",
    "cluster_info_mapping = {}\n",
    "\n",
    "# Use dfs_por_estado['df_1'] instead of df\n",
    "for cluster in dfs_por_estado['df_1']['cluster'].unique():\n",
    "    # Find the most frequent accident type within each cluster\n",
    "    most_frequent_accident_type = dfs_por_estado['df_1'][dfs_por_estado['df_1']['cluster'] == cluster]['TIPACCID'].mode().iloc[0]\n",
    "\n",
    "    # Find the most frequent color within each cluster\n",
    "    # most_frequent_color = dfs_por_estado['df_1'][dfs_por_estado['df_1']['cluster'] == cluster]['color'].mode().iloc[0]  # Assuming you have a 'color' column\n",
    "    # Assuming you don't have a color column comment out the color part\n",
    "\n",
    "    #cluster_info_mapping[cluster] = {'accident_type': most_frequent_accident_type, 'color': most_frequent_color}\n",
    "    # Removing the color from the dictionary\n",
    "    cluster_info_mapping[cluster] = {'accident_type': most_frequent_accident_type}\n",
    "\n",
    "# Print the mapping\n",
    "for cluster, info in cluster_info_mapping.items():\n",
    "    #print(f\"Cluster {cluster}: Accident Type - {info['accident_type']}, Color - {info['color']}\")\n",
    "    # Only printing the accident type\n",
    "    print(f\"Cluster {cluster}: Accident Type - {info['accident_type']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfQ_pG5rhGQp"
   },
   "outputs": [],
   "source": [
    "X_numericos = df[['TIPACCID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ge8RCLkChJaz"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "model = KMeans(random_state=1)\n",
    "visualizer = KElbowVisualizer(model, k=(1,10))\n",
    "visualizer.fit(X_numericos)\n",
    "visualizer.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e4tXGmtqgpV"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Iteramos sobre cada dataframe separado por estado\n",
    "for estado, dataframe in dfs_por_estado.items():\n",
    "    # Nos aseguramos de que las columnas de LATITUD y LONGITUD no tengan valores nulos\n",
    "    datos = df_sobremuestreado[['TIPACCID', 'ALIENTO', 'TOTMUERTOS']].dropna()\n",
    "\n",
    "    # Verificamos si hay suficientes datos para realizar agrupamiento\n",
    "    if len(datos) > 1:\n",
    "        # Configuramos el modelo K-Means (puedes ajustar n_clusters según sea necesario)\n",
    "        n_clusters = 5\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(datos)\n",
    "\n",
    "        # Asignamos las etiquetas de clúster al dataframe correspondiente\n",
    "        dataframe[\"Cluster\"] = kmeans.predict(dataframe[['TIPACCID', 'ALIENTO', 'TOTMUERTOS']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJ7D31OnAEPW"
   },
   "outputs": [],
   "source": [
    "# prompt: grafica cada cluster con su agrupacion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming you have 'dfs_por_estado' dictionary with DataFrames for each state\n",
    "# and each DataFrame has a 'Cluster' column assigned after KMeans clustering\n",
    "\n",
    "# Example for visualizing clusters in 'df_9'\n",
    "for estado, dataframe in dfs_por_estado.items():\n",
    "  if 'Cluster' in dataframe.columns:\n",
    "    # Create a scatter plot for the current state's DataFrame\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(dataframe['TIPACCID'], dataframe['TOTMUERTOS'], c=dataframe['Cluster'], cmap='viridis')\n",
    "    plt.xlabel('TIPACCID')\n",
    "    plt.ylabel('TOTMUERTOS')\n",
    "    plt.title(f'Clusters for State {estado.split(\"_\")[1]}')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "1Lsvp_nUr_nk"
   },
   "outputs": [],
   "source": [
    "# Creamos un diccionario para almacenar el tipo de accidente predominante en cada clúster por estado\n",
    "tipos_predominantes_por_estado = {}\n",
    "\n",
    "# Iteramos sobre cada dataframe separado por estado\n",
    "for estado, dataframe in dfs_por_estado.items():\n",
    "    if 'Cluster' in dataframe.columns and 'TIPACCID' in dataframe.columns:\n",
    "        # Agrupamos por Cluster y TIPACCIDETE para contar la frecuencia de cada tipo\n",
    "        agrupacion = dataframe.groupby(['Cluster', 'TIPACCID']).size().reset_index(name='Frecuencia')\n",
    "\n",
    "        # Encontramos el tipo de accidente predominante en cada clúster\n",
    "        predominios = agrupacion.loc[agrupacion.groupby('Cluster')['Frecuencia'].idxmax()]\n",
    "\n",
    "        # Guardamos los resultados en el diccionario\n",
    "        tipos_predominantes_por_estado[estado] = predominios[['Cluster', 'TIPACCID', 'Frecuencia']]\n",
    "\n",
    "        # Mostramos los resultados para este estado\n",
    "        print(f\"Estado {estado} - Tipos de accidentes predominantes por clúster:\")\n",
    "        print(predominios[['Cluster', 'TIPACCID', 'Frecuencia']])\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Estado {estado} no tiene la información necesaria para este análisis.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lCq6liNTrS6"
   },
   "outputs": [],
   "source": [
    "# prompt: crear sobremuestreo para \"TIPACCID\" en los parametros de (2, 4, 7, 10)\n",
    "\n",
    "import pandas as pd\n",
    "# Assuming 'df' is your DataFrame with 'TIPACCID' column\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Create a list of allowed TIPACCID values\n",
    "allowed_values = [2, 4, 7, 10]\n",
    "\n",
    "# Filter the DataFrame to keep only rows with TIPACCID in the allowed list\n",
    "df_filtered = df[df['TIPACCID'].isin(allowed_values)]\n",
    "\n",
    "# Separate the DataFrame by TIPACCID value\n",
    "dfs_by_tipaccid = {}\n",
    "for value in allowed_values:\n",
    "  dfs_by_tipaccid[value] = df_filtered[df_filtered['TIPACCID'] == value]\n",
    "\n",
    "# Oversample the minority classes (TIPACCID values)\n",
    "max_size = 0\n",
    "for value in allowed_values:\n",
    "  if len(dfs_by_tipaccid[value]) > max_size:\n",
    "    max_size = len(dfs_by_tipaccid[value])\n",
    "\n",
    "oversampled_dfs = []\n",
    "for value in allowed_values:\n",
    "  if len(dfs_by_tipaccid[value]) < max_size:\n",
    "    oversampled_df = resample(dfs_by_tipaccid[value],\n",
    "                              replace=True,\n",
    "                              n_samples=max_size,\n",
    "                              random_state=42)\n",
    "    oversampled_dfs.append(oversampled_df)\n",
    "  else:\n",
    "    oversampled_dfs.append(dfs_by_tipaccid[value])\n",
    "\n",
    "# Concatenate the oversampled DataFrames\n",
    "df_oversampled = pd.concat(oversampled_dfs)\n",
    "\n",
    "# Now 'df_oversampled' contains the oversampled data for TIPACCID values 2, 4, 7, and 10\n",
    "# You can continue with your clustering or other analysis using 'df_oversampled'\n",
    "df_oversampled.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg9d_hJlX3eP"
   },
   "outputs": [],
   "source": [
    "# prompt: muestrame las frecuencias de los TIPACCIDENTE\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'TIPACCID' column\n",
    "# Calculate the frequency of each TIPACCID value\n",
    "\n",
    "tipaccidente_frequencies = df_oversampled['TIPACCID'].value_counts()\n",
    "\n",
    "# Print the frequencies\n",
    "tipaccidente_frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzF6S1KOUJDn"
   },
   "outputs": [],
   "source": [
    "# prompt: ahora coloca ese nuevo sobre muestreo en el df llamandolo df_sobremuestreado\n",
    "\n",
    "df_sobremuestreado = df_oversampled\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
